---
title: "Assignment 6: ANCOVA HW"
author: "Leandro Ledesma"
date: "2024-10-16"
output: html_document
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(comment = "")
knitr::opts_chunk$set(warning = FALSE)

```

```{r load in packages, echo = FALSE}
library(tidyverse)
library(psych) # Describe
library(ggplot2)
library(car) # LevenesTest
library(kableExtra)
library(psych)
library(lmtest) # bptest (Bresuh-Pagan)
library(MASS) 
library(DescTools)  # EtaSq (eta-squared)
library(broom)
library(kableExtra)
library(emmeans) # emmeans()
library(interactions) # sim_slopes

```

### Load in the data

Description: This fictional data set, "Viagra", provides men's libido (and that of their partners) after having been administered different doses of viagra.
Variables: 

-	dose - Viagra dosage administered (Placebo, Low Dose, High Dose).

- libido - Participant's libido (measured over the course of one week).

- partnerLibido - Libido of participant's partner (measured over the course of one week).

```{r load in the data, echo = FALSE}
# load in the data
data <- read.delim("https://raw.githubusercontent.com/jasp-stats/jasp-data-library/main/Viagra/Viagra.csv", sep = ",")
```

### Examine the data

1.	What are the factor(s) in this example and How many levels (J) does each factor have? 

- There is one factor that represents the dosage of Viagra taken. It includes three levels (Placebo, Low Dose, High Dose). 

2.	What is the dependent variable in this example?  

- The outcome variable is the participant's libido.

3.	What is the covariate in this example?

- The covariate is the libido of the partner's libido

4.	Examine and briefly report relevant descriptive statistics, including measures of central tendency, variability, normality, and/or counts for each independent and dependent variable. Include your code and results.

- There are three levels to Viagra dosage with 9 subjects getting a placebo pill (30%), 8 getting a low dosage (27%), and 13 getting a high dosage (43%). The libido variable (outcome) is numeric and has a mean of 4.3 (median = 4) with a standard deviation of 1.96 (var = 3.83). The distribution of these scores is skewed to the right, indicating that most people tended to have libidos below the mean of the outcome. Partner's Libido also has a right skewed distribution, which also shows that most partner's libido was also lower than the average (mean = 2.73, sd = 1.86). 


5.	Check and report the correlations among predictors. Is multicollinearity an issue?

- Since the levels of the factor are ordinal (Placebo, Low Dose, High Dose), we can keep them as "numeric" variables that are ranked and correlate them to the covariate using Spearman's Rank Correlation. The correlation coefficient indicates no multicollinearity between the predictors because the correlation is not that strong (r = -0.32)

```{r examine the data, out.width = "49%"}
# Use the glimpse function to understand the data better
glimpse(data)

# Convert libido into a factor
data$dose <- as.factor(data$dose)

# Obtain the frequency of each level of the factor
table(data$dose)

# Get some descriptives of the numeric variables
describe(data$libido)
describe(data$partnerLibido)


hist(data$libido)
hist(data$partnerLibido)

# Correlate Libido and partner libido
cor(as.numeric(data$dose), data$partnerLibido, method = "spearman")

```

### Hypotheses

6.	Write the null hypotheses as they relate to the population means.

- $H_{0} : \mu_{1} = \mu_{2} = \mu_{3}$ (At the adjusted means)

7.	Write the alternative hypotheses as they relate to the population means.
 
- $H_{A}:\mu_{j}\neq\mu_{k}$ (At the adjusted means)

8.	Using typical language, write the null hypothesis.

- Viagra dosage has no effect on a participant's libido no matter what their partner's libido is. 

9.	Using typical language, write the alternative hypothesis.

- Viagra dosage does have an effect on a participant's libido at any level of their partner's libido.


### Fit ANCOVA & Compare Models (10 pts)

10.	Fit the following models using Type I SS. 
a.	An empty model
b.	A model that includes only the covariate effects on the outcome.
c.	A model that includes covariate and main effects on the outcome.
d.	A model that includes covariate, main, and interaction effects.
11.	 Report your code and output.
12.	Using model outputs, compare the fit among models. Report your code and output.
13.	Based on your comparison, which model should you choose to interpret? 

- Using the Anova() function to compare the different models, the best one to interpret is the full model with the inclusion of the covariate, the main effects, and their interaction. This is because when building the model using Type I SS, the full model had a significantly smaller residual SS than the previous model without the interaction (p < .05). 

14.	Report the selected ANCOVA Table of Results, including all relevant SS, df, MS, F, and p values. You can use R or create a table by hand. Report in APA style.

- Two output tables were created- both saying the same information. I prefer the table that looks like a regression but to not lose points I am showing both. I used the APA Tables from https://apastyle.apa.org/style-grammar-guidelines/tables-figures/sample-tables to help me create these. 

```{r Fit the ANCOVA and compare the models}
# Convert dose into a factor
data$dose <- factor(data$dose)

# Check the contrasts of the main effect
contrasts(data$dose)

# Create an empty model 
empty.model <- lm(libido ~ 1,data)

# Create a model that includes only the covariate
covariateOnly.model <- lm(libido ~ partnerLibido, data)

# Create a model that includes only the main effect (for Levene's Test)
MainOnly <- lm(libido ~ dose, data)

# Create a model that includes the covariate and main effects
covariateMain.model <- lm(libido ~ partnerLibido + dose, data)

# Create a model with the covariate, main effects, and interaction
full.model <- lm(libido ~ partnerLibido * dose, data)
full.model.aov <- aov(libido ~ partnerLibido * dose, data)

# Compare the fit for these models (Type 1 SS)
anova(empty.model, covariateOnly.model, covariateMain.model, full.model) 


# Convert the summary of the regression into a dataset
full.model.sum_df <- broom::tidy(summary(full.model))
full.model.aov.sum_df <- broom::tidy(full.model.aov)

# Round the output
full.model.sum_df <- full.model.sum_df %>%
  mutate_at(c("estimate", "std.error", "statistic", "p.value"), ~round(.,2))

full.model.aov.sum_df <- full.model.aov.sum_df %>%
  mutate_at(c("df", "sumsq", "meansq", "statistic", "p.value"), ~round(.,2))

# Rename the variables
names(full.model.sum_df) <- c("Effect", "Estimate", "SE", "t", "p")
names(full.model.aov.sum_df) <- c("Source", "df","SS","MS", "F","p")

# Rename the rows
full.model.sum_df$Effect <- c("Intercept", "Partner's Libido", 
                                  "No Dose vs Low Dose",
                                  "No Dose vs High Dose",
                                  "Parner's Libido x Low Dose",
                                  "Partner's Libido x High Dose")

full.model.aov.sum_df$Source <- c("Partner's Libido",
                                  "Viagra Dosage",
                                  "Parner's Libido x Viagra Dosage",
                                  "Residuals")

# Print the table
full.model.aov.sum_df %>%
  kbl(caption = "ANCOVA Summary Table") %>%
  kable_classic(full_width = F, html_font = "Cambria")


full.model.sum_df %>%
  kbl(caption = "Regression Summary Table") %>%
  kable_classic(full_width = F, html_font = "Cambria") %>%
  footnote("F-statistic: 4.286 on 5 and 24 DF,  p-value: 0.006295")

```


### Assumption Check (10 pts). 
15.	List all assumptions of ANCOVA.

- Independent observations: We cannot have the same participant's data more than once when the data is in wide format.

- Normality of residuals: The residuals of the model need to look normally distributed.

- Homogeneity of variance: The variance of each level of the factor must be similar to each other.

- Linearity between Covariate and Outcome: There needs to be a linear relationship between the covariate and outcome variable.

- No multicollinearity: There must not be a strong relationship between the covariate and the predictor 

- Random Sampling: The subjects recruited into the study were sampled randomly. 

16.	Check all assumptions of ANCOVA and report your logic/results.

- Independent observations: We are assuming the observations each belong to a different person. It is difficult to confirm since there is no ID variable in the dataset. 

- Normality of residuals: The histogram and QQplot of the residuals visually look normally distributed. It also has a p value greater than .05 in the Shapiro-Wilk test, which further supports the errors are normally distributed.

- Homogeneity of variance: Visualization using box plots of the variance of the outcome for each of the three levels looks similar. Running Levene's test (p= ns) and the Breush-Pagan test (p=ns) also indicate that the variance of the levels are similar to each other. 

- Linearity Between Covariate and Outcome: This can be identified visually by creating a scatterplot with regression lines going through the dots of each respective group (level of the factor). This was done for the plot in Q17 and it looks like this assumption was met. 

- No multicollinearity: We assessed this in the beginning and found no multicollinearity

- Random Sampling: We are assuming the data were sampled at random. 

```{r checking assumptions of an ANCOVA, out.width= "49%"}

# Check for independence of observations
hist(resid(full.model))
plot(full.model, which = c(1, 2)) # the first and second plot
shapiro.test(resid(full.model))

leveneTest(MainOnly, center = median)
bptest(MainOnly)

data %>%
ggplot(aes(x = dose, y = libido)) +
  geom_boxplot() +
  theme_classic()

```


### Figure of Results (5 pts)
17.	Create a figure to show the results of the final model.

```{r creating the figure to show the results of the final model, out.width = "66%"}
data %>%
ggplot(aes(x = partnerLibido, y = libido, color = dose)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = F) +
  theme_classic()

```


### Contrasts & Simple Effects (10 pts)
18.	Use Effect Coding to examine the difference between doses.
- Effect coding was used by changing the contrasts of dose to a matrix of cbind(c(-1,1,0), c(-1,0,1)). This compares the mean difference of the placebo from the grand mean to the difference of low dose from the grand mean. The second contrast does the same except it is the placebo group compared to the high dose group.

19.	Use Dummy Coding to examine the difference between doses.
- Dummy coding was used by having the place group remain as zero while the other conditions were 1 in their respective contrast. This compares the mean of the placebo directly to low dosage and then the mean of placebo to high dosage in the second contrast, this gives more power. 

20.	Compute and report the simple effect of dose on libido at the mean value of partner libido.
- I used regression with a grand mean centered predictor (covariate) to obtain the simple effects of dose on libido at the mean of partner libido. Thus, the beta coefficients produced by the models should be the simple effects since they are the differences of libido when the covariate (partner's libido) is at its mean value.

- At the mean value of partner's libido, the expected value of the participant's libido in the placebo group is 2.67 and the expected value of the participant's libido in the low dosage group is 2.67 + 1.87 = 4.54, this the simple effect here is 1.87.

- At the mean value of partner's libido, the expected value of the participant's libido in the placebo group is 2.67 and the expected value of the participant's libido in the high dosage group is 2.67 + 2.01 = 4.68, this the simple effect here is 2.01.

21.	Compute and report the simple effect of dose on libido at partner libido=2.

- For this question I used emmeans() function from the emmeans package which was able to give me the estimated marginal means. I first obtained the estimated marginal means at the mean value of the covariate to compare it to my results from above- they were the same which gives me confidence I am correct. I then set the level of the covariate to equal 2 and calculated their estimated marginal means, which functions the same as adjusted means of the outcome for the same level of the covariate. 

- When partner's libido is equal to 2, the expected value of the participant's libido in the placebo group is 2.12 and the expected value of the participant's libido in the low dosage group is 3.95, thus the simple effect here is 3.95- 2.12 = 1.83.

- When partner's libido is equal to 2, the expected value of the participant's libido in the placebo group is 2.12 and the expected value of the participant's libido in the high dosage group is 3.95, thus the simple effect here is 4.85 - 2.12 = 2.73.


22.	Does the slope between partner libido and libido differ across dose? Use simple slopes to examine this effect.

- Just by going off the simple effects, we can be pretty confident that there is an interaction in terms of slopes of viagra dosage, and the graph of the regression lines for each dose further confirms it. However, we can also test this statistically using the sim_slopes() function from the interactions package. The output shows us the slopes (estimates), which represent the expected value of the outcome at different levels of the factor and their associated p-value indicates whether this slope is statistically different from that of the reference (placebo)- essentially it is doing the same thing that was calculated from the regression with the grand mean centered covariate, except it includes the coefficients for dosage when the covariate is -1SD from the mean and +1SD from the mean. These p-values changing across the different levels of the covariate show that there is an interaction in place, specifically that the expected outcome of high dosage starts off being very different from the placebo at the lower values of the covariate but then tends to be similar to the placebo at the higher levels of the covariate.



```{r contrasts and simple effects}
# using effect coding
contrasts(data$dose) <- cbind(c(-1,1,0), c(-1,0,1))
contrasts(data$dose)
full.model.eff <- lm(libido ~ partnerLibido * dose, data)
summary(full.model.eff)

# Using dummy coding
contrasts(data$dose) <- cbind(c(0,1,0), c(0,0,1))
contrasts(data$dose)
full.model.dum <- lm(libido ~ partnerLibido * dose, data)
summary(full.model.dum)

# Grand mean center the covariate
data$partnerLibido_gmc <- data$partnerLibido - mean(data$partnerLibido)

# Create a model with covariate grand mean centered
full.model.dum.gmc <- lm(libido ~ partnerLibido_gmc * dose, data)
summary(full.model.dum.gmc)

# Test this function to see if the results match that of the grand mean centered covariate regression from above
simple_effects_at_avg <- emmeans(full.model.dum, ~ dose, at = list(partnerLibido = mean(data$partnerLibido)))
simple_effects_at_avg

# Identify the estimated marginal means (adjusted means) when the covariate is equal to two
simple_effects_at_cov_2 <- emmeans(full.model.dum, ~ dose , at = list(partnerLibido = 2))
simple_effects_at_cov_2


# Calculate the simple slopes
sim_slopes(model = full.model, pred = dose, modx = partnerLibido)

```


### Interpretation & Write-up (5 pts)
23.	Using APA formatting, write a concise 1 paragraph report describing the models you tested, model fit, model fit comparisons, model assumptions, model results, contrasts and simple effects, and reference figures/tables relevant for interpreting model results. 


A One-way ANCOVA was conducted to test whether different levels of Viagra dosage (placebo, low dose, high dose) influenced subject's libido while controlling for the effects of their partner's libido. Model comparisons using Type I SS concluded that the full model comprised of the covariate, the factor, and their interaction produced the best fit since it had a significantly smaller residual sum of squares compared to the model without including the interaction as a predictor (p < .05). Our results indicated a main effect of dose *F*(2,24)= 5.16, p < .05; a main effect of partner's libido *F*(1,24)= 6.18, p < .05;, and a significant interaction effect *F*(2,24)= 4.18, p < .05. Dummy coding contrasts were used to compare the means of the outcome of low dose and high dose to the placebo (respectively). Due to a significant interaction effect, the effect of Viagra dosage on libido depends on the level of partner's libido. A simple slopes analysis of dosage when the covariate is -1 SD from its mean showed that subject's libido for the high dosage group was statistically different from that of the placebo group (simple effect= 3.83, p < .05). Additionally, the simple slopes analysis showed no significant differences in subject's libido between the high dose and placebo (simple effects= .18, p > .05) groups when the covariate is +1 SD from its mean. Thus, these results indicate that the effect of high Viagra dosage on subject's libido is strongest when the subject's partner tends to have lower libido. Model assumptions were also met, the residuals were normally distributed from visual inspection and Shapiro-Wilk test was not significant, there was no heterscedasticity among the variances of the factor (Levene's test  p > .05), and each observation came from one single individual. 



### Theory & Concept (10 pts)

1.	True or false. ANOVA is generally robust to violations of normality.
- **a.	True**
- b.	False

2.	True or false. To be a true contrast, the sum of the contrasts must equal 1.
- a.	True
- **b.	False**

3.	A post-hoc analysis for testing all pairwise comparisons that is most powerful when the number of groups is large is:
- a.	Tukey
- **b.	Scheffe**
- c.	Bonferroni
- d.	Fisher’s LSD

4.	Which sums of squares type tests the unique contribution of each effect separately?
- a.	SS Type I
- b.	SS Type II
- **c.	SS Type III**

5.	The full ANCOVA model shown below defines separate slopes for each group to allow for group differences in the relationship between the covariate and the dependent variable.
 
 $Y_{ij} = \mu + \alpha_{j} + \beta X_{ij} + \epsilon_{ij}$
 
- a.	True
- **b.	False**







